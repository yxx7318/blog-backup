# 架构

## 整体介绍

- 对于现在主流的前后端开发来说，其可以分为前端和后端两个部分，再加一个通信协议，组成了基本的互联网服务：
  - 前端：万物基于`"浏览器"(谷歌)`
  - 后端：万物基于`"C++"`
  - 协议：互联网通信协议`HTTP`和`HTTPS`
  - 网关：`Nginx`

## 前端

**历史渊源**：在早期的互联网服务中，由于带宽限制、磁盘限制等诸多因素，绝大多数互联网服务其实都是以浏览器的方式存在的。而浏览器支持的语言是`HTML`、`CSS`、`JS`，所以这三剑客的地位举足轻重，造就了其在前端开发中的绝对主导地位

### 开发现状

> 在前端开发中，前端分为原生开发和通用开发

**原生开发**：原生开发就是基于对应的操作系统去写此系统支持的展示样式语言，这样的样式语言一般都会在一定程度上去借鉴浏览器的标签设计思路，像是基于`xml`的样式语言，其实都是有对`HTML`进行过借鉴的，与此同时对自己的操作系统进行了一定优化，以体现操作系统的特色，或者满足特定的用户需求

**通用开发**：通用开发就是通过编写一套代码，通过增加中间件的方式让这一套代码适配所有的平台。

> 那这种方式是怎么实现的呢？有两种方式

- **通过浏览器**：因为浏览器的一个核心作用就是让编写的`HTML`、`CSS`、`JS`代码**在每一个操作系统平台之间做到显示逻辑统一**，这依托于强大的浏览器内核。
  - 通用开发的解决方案就可以依赖于浏览器内核，通过给自己开发的应用内置一份浏览器内核，然后让开发人员写一套代码，在加载应用之前先启用浏览器内核，由浏览器内核去解析代码，通过浏览器跨平台的特性实现了通用开发。
  - 所以`electron`开发应运而生，基于`chrome`内核去进行开发。
  - 值得注意的是，在早期浏览器内核还没有被谷歌大一统的时候，那时候相同的代码可能给不同的浏览器内核会有不同的展示效果。当时有一个段子，怎么让程序员奔溃——适配IE浏览器，这就是因为IE浏览器的内核和谷歌浏览器的内核不一样，相同的代码会有不同的展示效果，所以不得不针对IE做很多特殊处理，现在IE都退出市场了，基本只要考虑适配谷歌浏览器内核了

- **通过编译器**：通过**将开发人员的代码去进行解析编译成指定操作平台的原生代码**，实现通用开发。
  - `uniapp`走的就是这条路，开发者只需要编写一套Vue代码，然后通过`uniapp`去进行编译，可以编译成`Web`、`H5`，`Android`、`IOS`等不同的操作系统端，本质上都是依托于`uniapp`的编译器编译成对应平台的原生代码

**通用开发优劣**：

- **通过浏览器**：其最大的优势就是对比通过编译器的方式，几乎不需要考虑跨平台兼容性问题，因为背后有极其强大的谷歌团队做兼容和适配，只需要确保自己编写的代码没有问题即可，开发效率很高。但是带来的后果就是，性能要求高，谷歌浏览器的内核的复杂程度完全不亚于任何一个操作系统，很多情况下只用它做一个基本得不能再基本的样式展示，有些"杀鸡焉用牛刀"的感觉。谷歌内核会非常占用用户的性能、磁盘、运行空间，可能得益于芯片性能的发展迅速，所以性能的考虑优先级不高。
- **通过编译器**：其最大的优势就是打包后的空间可以控制得很小，因为会编译成目标操作系统的语言，所以操作系统自带了"解释器"，而不用像通过浏览器开发的方式把整个浏览器放入打包后的文件中。缺点就是开发人员考虑的需要的更多一些，需要更多的考虑不同平台的兼容问题。

> 那能不能把两者的优点结合一下呢？其实可以结合，只要在每个操作系统里面都放入一个谷歌浏览器内核，然后应用把前端代码传给这个浏览器内核，那软件就不用在打包时把内核打包进去了，操作系统也能在内核层面对浏览器内核进行性能优化，但是很多大一些的互联网公司都不配合。为什么呢？
>
> 有两大原因：
>
> - 大的互联网公司早就对浏览器内核进行了深入的修改和定制，不想使用使用谷歌原本的浏览器内核，因为有些特性只有**自己基于谷歌浏览器自研的内核**支持，所以打包的时候一定要带
> - 大一点的互联公司需要一定程度上保证兼容性问题，需要保证版本的统一。操作系统的浏览器内核更新缓慢，因为操作系统嵌入的浏览器内核往往都是很多年前的浏览器内核了，操作系统要考虑适配和优化问题，所以不可能和谷歌浏览器同步发布。最重要的是，这样的方式导致每个用户的操作系统如果版本号不一致，那内嵌的浏览器版本就有可能不一致，使用操作系统的浏览器内核就有可能给用户造成不一样的展示效果了，但是内嵌浏览器内核就不会有这种问题了，浏览器内核版本是软件版本控制的，也就是控制权在自己公司手里，这样就能够进一步减少适配性问题
>
> 除了这两个原因之外，还有安全考量等一些方面的顾虑导致大的互联网公司都是会给自己的应用打包指定的浏览器内核

**自动化**：

对于很多操作"自动化"技术来说，由于前端布局文件的存在，所以可以将自动化操作分为**UI自动化和图形自动化**，自动化都是通过代码去模拟用户操作，首要解决的就是定位问题

- UI自动化就是获取布局文件的操作对象，通过模拟用户界面上的交互来执行自动化任务，像HTML一样，里面的每个元素都是写在了文件中了的，只要获取到节点之后，就可以模拟用户执行自动化操作了，类似于"**代码读代码**"
- 图形自动化就是指不依赖于UI组件的自动化操作，它直接操作图形界面，而不是通过UI元素。通过获取渲染后的展示效果，通过图形相似度进行节点定位，然后就可以模拟用户执行自动化操作了，类似于"**代码读结果**"

所以一般UI自动化的效率比图形自动化的效率会高非常多，甚至于自动化时都看不到"运行效果"，而图形自动化则是必须要有"运行效果"才能进行自动化

## 后端

**历史渊源**：C语言作为一门划时代的高级语言，具有非常多的优秀特性。`C++`在C语言的基础上扩充了C语言的特性，让`C++`可以拥有极其强大的性能的同时可以在各个领域发挥其作用，所以历史渊源导致C语言和C++使用的人数和操作系统支持都非常广泛

### 开发现状

**跨平台实现**

虽然C++代码运行在服务器具有很强的性能和并发支持能力，但`C++`有几个问题

- 首先就是它的学习周期十分的长，可以认为是最难的高级语言也不为过
- 而且由于C语言不支持真正意义上的"跨平台"，所以`C++`也不支持"跨平台"，所以为了在保证性能的同时提升开发的效率，C语言的跨平台特性相较而言很弱，C语言本质上**只是一门语法规范**，是由国际组织定义了C语言的语法、关键字、标准库等
- 而C语言又有众多的编译器，每个编译器的编译方式又存在细微差距，这些细微差距就会导致不同平台，代码运行效果可能不一致，甚至报错
- 为了解决这个问题，能够跨平台语言都是因为有团队专门做了适配的，所以像`Java`，`Python`等编程语言其实都是对`C++`的封装，通过使用对应的`编译器`、`解释器`来将`Java`或`Python`翻译成对应平台能够运行的命令，类似于前端的"浏览器"一样，实现了一套代码，不同平台，相同效果

如何跨平台呢？

- 首先为什么可以运行一门编程语言呢？
- 像是`Windows`原生支持`bat`脚本，`Linux`原生支持`shell`脚本，这都是**因为操作系统原生支持这些语言**，也就是在内核里面带了代码的运行环境
- 同理，想要运行`Java`、`Python`也需要运行环境，所以不能像在`windows`平台一样直接运行`bat`脚本
- 因为这些语言很多时候操作系统内核中都不会带这些语言的编译器和解释器，所以没有环境，也就无从谈起运行了

所以像`Java`团队，其实相当于给了一个**代码编写规范**，然后团队**给每个操作系统都做一层适配**，将`Java`代码翻译成对应平台能够执行的命令，`Java`代码就可以实现跨平台了，而这个工具就是`Java`的`JVM`

### 强弱语言

现在的高级语言其实可以分为两大类，强类型语言，像`Java`等，弱类型语言，像`Python`、`Php`，`JavaScript`等，两者简单的区别为：

- 在强类型语言中，**变量必须声明其类型**，并且在编译时，类型必须明确且一致。类型错误通常在编译阶段就会被捕获
- 弱类型语言通常更加灵活，**变量不需要显式声明类型**，类型可以根据上下文自动推断或转换
- 两种类型的语言在处理相同的任务时，强类型语言性能往往都会比弱类型语言要强

在后端语言的选择中，非常重要的一个点就是，需要考虑**语言代码的可维护性和性能**，这些都是弱类型语言所缺少的

- **可维护性**：后端代码的操作会直接或者间接的影响用户的信息，对于拥有一定体谅的用户规模的互联网服务来说，用户信息是至关重要的，还有支付服务，这都是核心重要的模块是不能出任何差池的，前端生产环境错误可能只是影响给用户的页面展示效果，但是后端生产环境错误影响的就是信息泄露或者数据丢失，所以后端代码的可维护性显得至关重要了，强类型语言可以在编译阶段就捕获一些错误，对于对象的属性也会在编写阶段就清晰，而不是运行后才知道对象的类型
- **性能**：
  - 强类型语言的性能普遍都要比弱类型强，因为弱类型语言**需要对变量的类型进行非常多的推断和转换**，编译器也很难对代码做很多针对性的优化，更别提有些弱类型语言还需要引入第三方模块才能支持多线程(例如：`Php`，像`Js`在浏览器运行时也是"单线程")，这对并发的支持是非常致命的，导致运行效率极其低下，在并发数量的支持上可以**拉出上百倍的差距**
  - 对于前端代码来说，其**代码运行和图形的渲染都是消耗的用户端的算力**，但是用户的每一次操作和请求的处理，**消耗的都是服务端的性能**，所以服务端能够支持的并发数越多，也能够很大程度上降低服务器的成本

弱类型语言的优点就是开发效率普遍很高，强类型语言写起来有些"繁琐"。对于用户数量不多的互联网服务使用弱类型语言开发后端确实可以节约成本，但是在用户规模起来之后，一般都会选择重构，换为强类型语言

## 协议

### HTTP

> 假设前端服务和后端服务都有了，两者怎么通信呢？此时就需要使用HTTP协议了

HTTP协议由如下几个部分组成：

- 请求行：包含了请求方法，请求URI，和HTTP版本
- 请求头：包含了一些关于请求的元数据
- 空行：请求头和请求体之间需要有一个空行，用于分隔
- 请求体：包含了请求的具体内容

通过HTTP协议，用户可以发送请求到服务器，服务器可以返回数据给用户，由于服务端的存在，用户就算一些存储在本地的数据丢失了，通过云服务器也能够将恢复

### HTTPS

> 由于数据的传输是可以被截取的，截取后直接进行对应的解码就可以还原信息。所以很容易被人获取到用户和服务器的通信数据，怎么解决安全通信问题呢？此时就需要使用HTTPS协议了

HTTPS其实就是在HTTP的基础上加了一层`SSL`，也就是数字签名，在进行通信之前，通过**交换密钥、生成密钥**的方式，将传输的数据进行加密，让数据的盗取者就算拿到数据，**也是一段乱码**，实现了对数据的加密通信

## 网关

> 网关是处于前端和后端中间的连接处，可以对请求进行**反向代理、请求过滤**等

为什么需要网关呢？以Nginx为例，Nginx可以解决很多问题

- 用户需要能够使用互联网服务，就需要把`HTML`、`CSS`、`JS`代码发送给用户，那怎么发送给用户呢？
  - 那就需要提供一个ip和端口，让用户在访问这个ip(域名本质上是方便定位ip的)和端口时返回给用户这些代码，然后解析这些代码就可以了。Nginx就可以把静态资源文件返回给用户。
- 应用程序和用户直接进行HTTPS通信存在性能较弱、如果有很多不同类型的应用程序可能会存在TLS版本不一致的兼容性等问题，怎么办呢？
  - 由网关和用户进行进行HTTPS通信，网关和各个应用程序之间进行指定的HTTP、HTTPS通信，网关将用户的信息发送给后端应用程序，将应用程序返回的信息再发送给用户。Nginx可以实现这些功能
- 一台服务器无法支撑起很多用户的请求，怎么办？
  - 如果可以把这些请求分散到各个服务器上，那么单台服务器的压力就下去了，也就能够支持更多的并发了。Nginx就可以通过负载均衡的方式去把请求分发到各个后端服务器上
- 如果服务受到DDOS网络攻击怎么办？
  - 可以在网关就封禁一些国外ip，限制每个ip的HTTP连接数量，每个连接线程的带宽，从而不印象给正常的用户提供服务。Nginx也可以做到这些

## 安全

> 在服务器上运行的程序，其实都需要注意一个问题，那就是安全问题

因为运行在服务器上的程序其实是有很高的权限的，比如读写服务器上的系统文件、操作系统进程等，这是为了满足开发人员复杂的业务需求的。

- 很多开发人员其实很容易忽略自己的`Java`程序其实很多时候是对**服务器有很高的操作权限**，但是这种操作一般是不能提供给用户的
- 用户能够做的应该就是后端代码里面，也就是业务逻辑里面能够允许操作的范围，像是文件上传
- 但是万一一个应用程序有漏洞，黑客就可能通过漏洞让拥有较高权限的应用程序去对服务器执行一些非法操作，像是获取服务器的所有文件，关闭一些系统进程等恶意操作

这些安全问题其实也存在于第三方包中，下载使用了一些恶意的第三方包，完全可能在代码运行的时候，数据库信息泄露、服务器奔溃等，在实际开发中也需要注意安全问题

> 就像我会这么做比喻，如果前端服务是给用户看能够买什么样的东西，那后端服务就是记录用户拿了什么东西，而安全服务就是让用户不能拿别人的东西
