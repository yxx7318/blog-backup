# 爬取携程景点信息

## 携程景详细信息

```python
import urllib.request
import os  # os.mkdir("单级目录") os.makedirs("多级目录")
import time
import random
from lxml import etree
import openpyxl

url_base = 'https://you.ctrip.com/'

headers = {
    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,'
              'application/signed-exchange;v=b3;q=0.9',
    'accept-language': 'zh-CN,zh;q=0.9',
    'cache-control': 'max-age=0',
    'if-none-match': '"23b775-EbiX/W62/aZI+mWTComqGPWFNBQ"',
    'sec-ch-ua': '" Not A;Brand";v="99", "Chromium";v="8"',
    'sec-ch-ua-mobile': '?0',
    'sec-fetch-dest': 'document',
    'sec-fetch-mode': 'navigate',
    'sec-fetch-site': 'same-origin',
    'sec-fetch-user': '?1',
    'upgrade-insecure-requests': '1',
    'referer': 'https://you.ctrip.com/',
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36 SLBrowser/8.0.1.3162 SLBChan/101',
}

# 这里省略了cookie的内容需要手动添加，并修改后面方法的随机函数的值
cookie = ['']


def null(variable):
    if variable is None:
        return ''
    else:
        if len(variable) > 0:
            return variable[0]
        else:
            return ''


# 创建主文件目录，并下载到主页面
def folder_main(folder_main_name):
    # 创建主文件夹
    folder(folder_main_name)
    # 获取主页面信息
    if os.path.exists("携程/携程.html"):
        return
    else:
        with open('携程/携程.html', 'w', encoding='utf-8') as fp:
            # 修改后缀可以修改基准
            fp.write(https(url_base))


# 返回页面信息
def https(url=None):
    headers['cookie'] = cookie[random.randint(0, 0)]
    request = urllib.request.Request(url=url, headers=headers)
    response = urllib.request.urlopen(request)
    return response.read().decode("UTF-8")


# 创建目录
def folder(folder_name):
    if os.path.exists(folder_name):
        print("目录\"" + folder_name + "\"已存在，不可重复创建")
    else:
        os.makedirs(folder_name)
    time.sleep(0.3)


# 处理本地html文件信息，返回tree
def parser_information(address):
    parser = etree.HTMLParser(encoding="UTF-8")
    return etree.parse(address, parser=parser)


# 处理发送过来的html信息，返回tree
def HTML_information(url):
    return etree.HTML(https(url))


def picture(picture_url, picture_filename):
    # 取出图片后缀作为名称(只取后面一截)
    picture_url_suffix = picture_url.split("/")[-1]
    # 拼接图片地址
    picture_filename = picture_filename + "/" + picture_url_suffix
    # 下载图片
    urllib.request.urlretrieve(url=picture_url, filename=picture_filename)
    time.sleep(0.3)


if __name__ == '__main__':
    # 文件夹目录国内-->省-->市：国内/广东/广州/页数/长隆野生动物世界
    big_start = int(input("输入省起始"))
    big_end = int(input("输入省结束(最大29)"))
    small_start = int(input("输入市起始"))
    small_end = int(input("输入市结束(最大20)"))
    page_start = int(input("输入爬取的起始页数"))
    page_end = int(input("输入爬取的终止页数"))
    scenic_number = int(input("输入每页爬取的数量(最大10)"))

    # # 地区对应的url：shanghai2
    # url_place_list = ["shanghai2"]
    # # 第一页对应page为1
    # page = 1
    # # 每个地区完整的url：https://you.ctrip.com/sight/shanghai2.html
    # url_full = url_base + 'sight/' + url_place_list[0] + '.html'
    # # 地区页面对应的地址，也就是需要爬取的目标页面：https://you.ctrip.com/sight/shanghai2/s0-p1.html
    # url_target = url_full.replace('.html', '') + '/s0-p' + str(page) + '.html'
    # # 地区页面所对应的旅游景点的关键字：762
    # url_scenic_list = ['762']
    # # 地区页面所对应的旅游景点的地址：https://you.ctrip.com/sight/shanghai2/762.html
    # url_scenic = url_target.replace('s0-p1.html', '') + url_scenic_list[0] + '.html'

    # 创建按主目录，并下载主页面
    folder_main("携程/国内")
    # 循环省份
    for i in range(big_start - 1, big_end):
        # 获取省名称
        tree = parser_information("携程/携程.html")
        economize_name = tree.xpath('//div[@class="city-selector-tab-main-city-title"]/text()')
        # 通过省获取市名称和地址
        market_name = tree.xpath('//div[@class="city-selector-tab-main-city-title" and text()="' + economize_name[
            i] + '"]/../div[@class="city-selector-tab-main-city-list"]/a/text()')
        # 获取到粗略地址
        market_url = tree.xpath('//div[@class="city-selector-tab-main-city-title" and text()="' + economize_name[
            i] + '"]/../div[@class="city-selector-tab-main-city-list"]/a/@href')
        # 获取到每个市详细页地址
        for n in range(len(market_url)):
            market_url[n] = market_url[n].replace("place", "sight")
        # 循环城市
        for j in range(small_start - 1, small_end):
            # 不下载当前城市的景点略缩页面，直接分析页面，获取页面跳转信息
            tree = HTML_information(market_url[j])

            # 循环页面，获取此页面的信息
            for page in range(page_start - 1, page_end):
                # 如果是第一页，不需要拼接地址
                if page == 0:
                    print("第一页就是此城市的首页", market_url[j])
                else:
                    obj_url = market_url[j].replace('.html', "/s0-p" + str(page + 1) + ".html")
                    tree = HTML_information(obj_url)

                # 获取此页景点略缩页面数据——>attractions_name(景点名)、thumbnail(略缩图)(220*140)
                # heat(热度)
                attractions_name = tree.xpath('//div[@class="list_mod2"]//dt/a/@title')
                thumbnail = tree.xpath('//div[@class="leftimg"]/a/img/@src')
                # address = tree.xpath('//div[@class="list_mod2"]//dd[@class="ellipsis"]/text()')
                # # 去除地址前面的换行
                # for n in range(len(address)):
                #     address[n] = address[n].replace('\n', '')

                heat = tree.xpath('//b[@class="hot_score_number"]/text()')
                # 所有景点的url，用于进入详细页
                attractions_url = tree.xpath('//div[@class="rdetailbox"]/dl/dt/a[@target="_blank"]/@href')

                # 循环创建文件夹，每个页面一次(创建文件夹时一起把略缩图下了)
                for n in range(scenic_number):
                    folder_name_thumbnail = "携程/国内/" + economize_name[i] + "/" + market_name[j] + "/" + str(
                        page + 1) + "/" + attractions_name[n] + "/thumbnail"
                    folder(folder_name_thumbnail)
                    # 循环保存略缩图
                    picture(thumbnail[n], folder_name_thumbnail)

                # 循环进入景点详细页面(景点数量为一页十个)
                for k in range(scenic_number):
                    # 获取景点详细页面数据——>官方电话(phone_number)、detailed(详细图四张)(512*391)、景点描述摘要(summary)、address(详细地址)、
                    # 景点描述内容(file_id)、tags(标签)、preferential_policy(优待政策)、opening_hours(开放时间)、service_facilities(服务设施)、景点评价得分(appraise_score)
                    tree = HTML_information(attractions_url[k])
                    print("访问的景点url地址", attractions_url[k])
                    address = tree.xpath(
                        '//p[@class="baseInfoTitle" and text()="地址"]/../p[@class="baseInfoText"]/text()')
                    address = null(address)
                    appraise_score = tree.xpath('//div[@class="commentScore"]/p[@class="commentScoreNum"]/text()')
                    appraise_score = null(appraise_score)

                    phone_number = tree.xpath(
                        '//p[@class="baseInfoTitle" and text()="官方电话"]/../p[@class="baseInfoText"]/text()')  # str
                    phone_number = null(phone_number)

                    # 因为python中的xpath支持的字符串长度有限，所以这里有4*2个结果(有些只有一张图)
                    detailed = tree.xpath('//div[@class="swiper-wrapper"]/div/@style')
                    # 对图片地址进行进一步的处理
                    for n in range(int(len(detailed) / 2)):
                        detailed[n] = detailed[n].split('(')[1].split(')')[0]

                    # 景点所有描述信息
                    all_text = tree.xpath('//div[@class="LimitHeightText"]//p//text()')
                    # 景点概要信息
                    summary = ''
                    if all_text is None:
                        file_id = ''
                    else:
                        # 将后面剩下的内容汇总为详细信息
                        file_id = ''
                        for n in range(0, len(all_text)):
                            if n == 0:
                                summary = all_text[0]
                            else:
                                file_id = file_id + all_text[n]

                    opening_hours = tree.xpath(
                        '//div[@class="moduleTitle" and text()="开放时间"]/../div[@class="moduleContent"]/text()')
                    opening_hours = null(opening_hours)

                    tags = tree.xpath('//div[@class="rank"]/p/text()')
                    tags = null(tags)

                    # 将多个优待政策汇总//div[@class="moduleTitle" and text()="优待政策"]/..//div[@class="moduleContentRow"]/text()
                    preferential_policy_list = tree.xpath(
                        '//div[@class="moduleContent"]/div[@class="moduleContentRow" and not(b)]/text()')
                    preferential_policy = ''
                    for n in range(len(preferential_policy_list)):
                        preferential_policy = preferential_policy + preferential_policy_list[n]

                    # 将多个服务设施汇总
                    service_facilities = ''
                    # 服务
                    service_facilities_one = tree.xpath(
                        '//div[@class="moduleTitle" and text()="服务设施"]/..//div[@class="moduleContentRow"]/b/text()')
                    # 详细(详细一般为服务的两倍，但是可能存在详细为空的情况)
                    service_facilities_two = tree.xpath(
                        '//div[@class="moduleTitle" and text()="服务设施"]/..//div[@class="moduleContentRow"]/b/../text()')
                    # 存储偏移量
                    num = 0
                    for n in range(len(service_facilities_one)):
                        m = n * 2 - num
                        # 因为为空就是两个"："同时出现，所以通过下一个判断
                        if m < len(service_facilities_two) - 1:
                            if service_facilities_two[m] == '：' and service_facilities_two[m + 1] != '：':
                                service_facilities = service_facilities + service_facilities_one[n] + \
                                                     service_facilities_two[m] + service_facilities_two[m + 1] + '，'
                            else:
                                service_facilities = service_facilities + service_facilities_one[n] + \
                                                     service_facilities_two[m] + ' ，'
                                num += 1
                        # 考虑最后一个为空的情况
                        if m == len(service_facilities_two) - 1 and service_facilities_two[m] == '：':
                            service_facilities = service_facilities + service_facilities_one[n] + \
                                                 service_facilities_two[m] + ' ，'


                    # 创建文件夹保存图片：略缩图：携程/国内/economize_name[i](省名)/market_name[j](城市名)/page/attractions_name[k](景点名)/thumbnail(略缩图)  详细图：直接在景点名下面

                    # 详细图地址
                    folder_name = "携程/国内/" + economize_name[i] + "/" + market_name[j] + "/" + str(page + 1) + "/" + \
                                  attractions_name[k]

                    time.sleep(0.5)

                    # 循环保存详细图
                    for n in range(int(len(detailed) / 2)):
                        picture(detailed[n], folder_name)

                    # print("打印省名称", economize_name[i], type(economize_name[i]))
                    # print("打印城市名称", market_name[j], type(market_name[j]))
                    # print("打印页数", page + 1)
                    # print("打印景点名称", attractions_name[k], type(attractions_name[k]))
                    # print("打印详细地址", address, type(address))
                    # print("打印景点评价得分", appraise_score, type(appraise_score))
                    # print("打印景点热度", heat[k], type(heat[k]))
                    # print("描述摘要", summary, type(summary))
                    # print("景点描述内容", file_id, type(file_id))
                    # print("打印开放时间", opening_hours, type(opening_hours))
                    # print("打印优待政策", preferential_policy, type(preferential_policy))
                    # print("打印服务设施", service_facilities, type(service_facilities))
                    # print("打印官方电话", phone_number, type(phone_number))
                    # print("打印标签", tags, type(tags))

                    # ws.append([economize_name[i], market_name[j], page + 1, attractions_name[k], address,
                    #            appraise_score, heat[k], summary, file_id, opening_hours, preferential_policy,
                    #            service_facilities, phone_number, tags])

                    # 保存进xlsx文档(不断写入，及时保存)

                    if os.path.exists("携程/数据表.xlsx"):
                        print("数据表已存在")
                    else:
                        # 新建新的工作簿
                        wb = openpyxl.Workbook()
                        # 加载工作表
                        ws = wb.active
                        # 命名单元格后再添加数据
                        ws['A1'] = "province_name"  # 省
                        ws['B1'] = "city_name"  # 城市
                        ws['C1'] = "page"  # 页数
                        ws['D1'] = "attractions_name"  # attractions_name(景点名)
                        ws['E1'] = "address"  # address(详细地址)
                        ws['F1'] = "appraise_score"  # 景点评价得分(appraise_score)
                        ws['G1'] = "heat"  # heat(热度)
                        ws['H1'] = "summary"  # 景点描述摘要(summary)
                        ws['I1'] = "file_id"  # 景点描述内容(file_id)
                        ws['J1'] = "opening_hours"  # opening_hours(开放时间)
                        ws['K1'] = "preferential_policy"  # preferential_policy(优待政策)
                        ws['L1'] = "service_facilities"  # service_facilities(服务设施)
                        ws['M1'] = "phone_number"  # phone_number(官方电话)
                        ws['N1'] = "tags"  # tags(标签)
                        wb.save("携程/数据表.xlsx")

                    # 加载工作簿
                    wb = openpyxl.load_workbook("携程/数据表.xlsx")
                    # 加载工作表
                    ws = wb.active
                    ws.append([economize_name[i], market_name[j], page + 1, attractions_name[k], address,
                               appraise_score, heat[k], summary, file_id, opening_hours, preferential_policy,
                               service_facilities, phone_number, tags])
                    wb.save("携程/数据表.xlsx")
                    # 结束后进入下一页
# pip install openpyxl -i https://pypi.douban.com/simple
# pip install lxml -i https://pypi.douban.com/simple

# address(详细地址)、官方电话(phone_number)
# attractions表需要的数据 attractions_name(景点名)、(city_id(所属城市id))、heat(热度)、景点描述摘要(summary)、景点描述内容(file_id)、景点评价得分(appraise_score)
# 开放时间(opening_hours)、preferential_policy(优待政策)、service_facilities(服务设施)
# tags表需要的数据tags(标签)
# price价格不知从哪里来

```

## 携程景点推荐信息

```python
import urllib.request
import os  # os.mkdir("单级目录") os.makedirs("多级目录")
import time
import random
from lxml import etree
import openpyxl

url_base = 'https://you.ctrip.com/'

headers = {
    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,'
              'application/signed-exchange;v=b3;q=0.9',
    'accept-language': 'zh-CN,zh;q=0.9',
    'cache-control': 'max-age=0',
    'if-none-match': '"23b775-EbiX/W62/aZI+mWTComqGPWFNBQ"',
    'sec-ch-ua': '" Not A;Brand";v="99", "Chromium";v="8"',
    'sec-ch-ua-mobile': '?0',
    'sec-fetch-dest': 'document',
    'sec-fetch-mode': 'navigate',
    'sec-fetch-site': 'same-origin',
    'sec-fetch-user': '?1',
    'upgrade-insecure-requests': '1',
    'referer': 'https://you.ctrip.com/',
    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/92.0.4515.131 Safari/537.36 SLBrowser/8.0.1.3162 SLBChan/101',
}

cookie = ['MKT_CKID=1681179085658.gg1p8.6ein; GUID=09031110118178005256; _RSG=Toa5wZhhTODJlEgR1FRnA8; '
          '_RDG=28b95d1b6d0ed326b812cd8c47424f25f4; _RGUID=d61daeb8-fa16-4c9d-82b1-6cf05ba8ebd3; _bfaStatusPVSend=1; '
          'MKT_Pagesource=PC; ibulanguage=CN; ibulocale=zh_cn; cookiePricesDisplayed=CNY; nfes_isSupportWebP=1; '
          'Hm_lvt_e4211314613fcf074540918eb10eeecb=1681186659; nfes_isSupportWebP=1; '
          'ASP.NET_SessionSvc=MTAuMTEzLjkyLjg4fDkwOTB8b3V5YW5nfGRlZmF1bHR8MTY0MjQwNjc4NTkwNQ; intl_ht1=h4=1_374791; '
          'Session=SmartLinkCode=alipay&SmartLinkKeyWord=&SmartLinkQuary=_UTF.&SmartLinkHost=openauth.alipay.com'
          '&SmartLinkLanguage=zh; Union=OUID=index&AllianceID=4897&SID=155952&SourceID=&createtime=1681629420&Expires'
          '=1682234220440; MKT_OrderClick=ASID=4897155952&AID=4897&CSID=155952&OUID=index&CT=1681629420442&CURL=https'
          '%3A%2F%2Fwww.ctrip.com%2F%3Fsid%3D155952%26allianceid%3D4897%26ouid%3Dindex&VAL={'
          '"pc_vid":"1681179085233.3jjant"}; MKT_CKID_LMT=1681980945129; '
          '_bfa=1.1681179085233.3jjant.1.1681980943788.1682055237180.30.277.1; '
          '_ubtstatus=%7B%22vid%22%3A%221681179085233.3jjant%22%2C%22sid%22%3A30%2C%22pvid%22%3A277%2C%22pid%22%3A0'
          '%7D; Hm_lpvt_e4211314613fcf074540918eb10eeecb=1682055239; '
          '_jzqco=%7C%7C%7C%7C1681980945338%7C1.521260233.1681179085650.1681980945007.1682055239137.1681980945007'
          '.1682055239137.undefined.0.0.253.253; '
          '__zpspc=9.33.1682055239.1682055239.1%232%7Cwww.baidu.com%7C%7C%7C%25E6%2590%25BA%25E7%25A8%258B%7C%23; '
          '_RF1=218.77.40.70; _bfi=p1%3D0%26p2%3D0%26v1%3D277%26v2%3D276; _bfaStatus=success; '
          '_pd=%7B%22_o%22%3A84%2C%22s%22%3A363%2C%22_s%22%3A0%7D']


def null(variable):
    if variable is None:
        return ''
    else:
        if len(variable) > 0:
            return variable[0]
        else:
            return ''


# 创建主文件目录，并下载到主页面
def folder_main(folder_main_name):
    # 创建主文件夹
    folder(folder_main_name)
    # 获取主页面信息
    if os.path.exists("携程/携程.html"):
        return
    else:
        with open('携程/携程.html', 'w', encoding='utf-8') as fp:
            # 修改后缀可以修改基准
            fp.write(https(url_base))


# 返回页面信息
def https(url=None):
    headers['cookie'] = cookie[random.randint(0, 0)]
    request = urllib.request.Request(url=url, headers=headers)
    response = urllib.request.urlopen(request)
    return response.read().decode("UTF-8")


# 创建目录
def folder(folder_name):
    if os.path.exists(folder_name):
        print("目录\"" + folder_name + "\"已存在，不可重复创建")
    else:
        os.makedirs(folder_name)
    time.sleep(0.3)


# 处理本地html文件信息，返回tree
def parser_information(address):
    parser = etree.HTMLParser(encoding="UTF-8")
    return etree.parse(address, parser=parser)


# 处理发送过来的html信息，返回tree
def HTML_information(url):
    return etree.HTML(https(url))


def picture(picture_url, picture_filename):
    # 取出图片后缀作为名称(只取后面一截)
    picture_url_suffix = picture_url.split("/")[-1]
    # 拼接图片地址
    picture_filename = picture_filename + "/" + picture_url_suffix
    # 下载图片
    urllib.request.urlretrieve(url=picture_url, filename=picture_filename)
    time.sleep(0.3)


if __name__ == '__main__':
    big_start = int(input("输入省起始"))
    big_end = int(input("输入省结束(最大29)"))
    small_start = int(input("输入市起始"))
    small_end = int(input("输入市结束(最大20)"))

    # 创建按主目录，并下载主页面
    folder_main("携程/国内")
    for i in range(big_start - 1, big_end):
        # 获取省名称
        tree = parser_information("携程/携程.html")
        economize_name = tree.xpath('//div[@class="city-selector-tab-main-city-title"]/text()')
        # 通过省获取市名称和地址
        market_name = tree.xpath('//div[@class="city-selector-tab-main-city-title" and text()="' + economize_name[
            i] + '"]/../div[@class="city-selector-tab-main-city-list"]/a/text()')
        # 获取到粗略地址
        market_url = tree.xpath('//div[@class="city-selector-tab-main-city-title" and text()="' + economize_name[
            i] + '"]/../div[@class="city-selector-tab-main-city-list"]/a/@href')

        for j in range(small_start - 1, small_end):
            # 不下载当前城市的景点推荐页面，直接分析页面，获取页面跳转信息
            tree = HTML_information(market_url[j])

            # 图片保存目录 国内/省名称/市名称/推荐/大图
            folder_name = "携程/国内/" + economize_name[i] + "/" + market_name[j] + "/" + "推荐/大图"
            folder(folder_name)

            english_name = tree.xpath('//div[@class="destination-name-en"]/text()')

            attractions_name = tree.xpath('//p[@class="title"]/text()')

            attractions_url = tree.xpath('//a[@class="guide-main-item"]/@href')

            picture_big = tree.xpath('//div[@class="city-head-image-container"]/img/@src')

            # 保存大图
            picture(picture_big[0], folder_name)

            picture_small = tree.xpath('//div[@class="guide-main-item-top"]/@style')

            if os.path.exists("携程/推荐表.xlsx"):
                print("数据表已存在")
            else:
                # 新建新的工作簿
                wb = openpyxl.Workbook()
                # 加载工作表
                ws = wb.active
                # 命名单元格后再添加数据
                ws['A1'] = "city_name"  # 城市
                ws['B1'] = "province_name"  # 省
                ws['C1'] = "english_name"  # 英文名
                ws['D1'] = "attractions_name"  # attractions_name(景点名)
                ws['E1'] = "appraise_score"  # 景点评价得分(appraise_score)
                ws['F1'] = "comments"  # 景点点评数量，城市热度
                ws['G1'] = "summary"  # 景点描述摘要(summary)
                ws['H1'] = "file_id"  # 推荐景点的图片的id
                wb.save("携程/推荐表.xlsx")

            # 加载工作簿
            wb = openpyxl.load_workbook("携程/推荐表.xlsx")
            # 加载工作表
            ws = wb.active

            # 循环六次，存入所有信息
            for k in range(6):
                # 根据链接获取，包含当前景点的评分和点评数量(https://you.ctrip.com/sight/hongkong38/3339.html)
                all_text = tree.xpath('//a[@href="' + attractions_url[k] + '"]//p[@class="tag"]//text()')
                # 获取评分
                appraise_score = all_text[0]
                # 获取点评数量
                comments = all_text[2]
                # 如果结尾存在w，即为万，需要转换
                if "w" in comments:
                    comments = float(comments.replace("w", '')) * 10000
                else:
                    comments = int(comments)
                # 获取概述(可能为空)
                summary = tree.xpath('//a[@href="' + attractions_url[k] + '"]//p[@class="txt"]/text()')
                summary = null(summary)

                picture_small[k] = picture_small[k].split('(')[1].split(')')[0]
                # 创建"小图"存储目录
                folder("携程/国内/" + economize_name[i] + "/" + market_name[j] + "/" + "推荐/" + attractions_name[k])
                # 去掉后缀"大图"
                picture(picture_small[k], folder_name.replace("大图", attractions_name[k]))

                # print(market_name[j], economize_name[i], english_name[0],
                #            attractions_name[k], appraise_score, comments, summary)
                # 存入一个推荐景点信息
                ws.append(
                    [market_name[j], economize_name[i], english_name[0], attractions_name[k], appraise_score, comments,
                     summary, picture_small[k].split("/")[-1]])
            wb.save("携程/推荐表.xlsx")

# 城市大图picture_big、景点图片picture_small
# 需要的数据——城市名称city_name(主键)、城市拼音english_name、城市推荐景点名称attractions_name、
# 景点评分appraise_score、景点点评数(作为城市的热度)comments、景点概述summary
# 景点id由数据库处理、城市id由数据库处理

```

## 携程景点省份和城市

```python
import os  # os.mkdir("单级目录") os.makedirs("多级目录")
from lxml import etree
import openpyxl


# 处理本地html文件信息，返回tree
def parser_information(address):
    parser = etree.HTMLParser(encoding="UTF-8")
    return etree.parse(address, parser=parser)


if __name__ == '__main__':
    if os.path.exists("携程/城市表.xlsx"):
        print("城市表已存在")
    else:
        # 新建新的工作簿
        wb = openpyxl.Workbook()
        # 加载工作表
        ws = wb.active
        # 命名单元格后再添加数据
        ws['A1'] = "province_name"  # 省
        ws['B1'] = "city_name"  # 城市
        ws['C1'] = "url_english_name"  # 城市英文名称
        wb.save("携程/城市表.xlsx")

    if os.path.exists("携程/省份表.xlsx"):
        print("省份表已存在")
    else:
        # 新建新的工作簿
        wb = openpyxl.Workbook()
        # 加载工作表
        ws = wb.active
        # 命名单元格后再添加数据
        ws['A1'] = "province_name"  # 省
        ws['B1'] = "city_name"  # 城市
        ws['C1'] = "english_name"  # 城市英文名称
        wb.save("携程/省份表.xlsx")

    # 获取省名称
    tree = parser_information("携程/携程.html")
    economize_name = tree.xpath('//div[@class="city-selector-tab-main-city-title"]/text()')

    # 循环省
    for i in range(len(economize_name)):
        # 通过省获取市名称和地址
        market_name = tree.xpath('//div[@class="city-selector-tab-main-city-title" and text()="' + economize_name[
            i] + '"]/../div[@class="city-selector-tab-main-city-list"]/a/text()')
        # 获取到粗略地址
        market_url_english_name = tree.xpath(
            '//div[@class="city-selector-tab-main-city-title" and text()="' + economize_name[
                i] + '"]/../div[@class="city-selector-tab-main-city-list"]/a/@href')
        # 根据省获取循环获取市
        for j in range(len(market_name)):
            # 循环获取到城市英文名称后缀
            for k in range(len(market_url_english_name)):
                market_url_english_name[k] = market_url_english_name[k].split("/")[-1].replace(".html", "")

            # 加载工作簿
            wb = openpyxl.load_workbook("携程/城市表.xlsx")
            # 加载工作表
            ws = wb.active
            ws.append([economize_name[i], market_name[j], market_url_english_name[j]])
            wb.save("携程/城市表.xlsx")

    # 循环保存省份表
    for i in range(len(economize_name)):
        # 加载工作簿
        wb = openpyxl.load_workbook("携程/省份表.xlsx")
        # 加载工作表
        ws = wb.active
        ws.append([economize_name[i]])
        wb.save("携程/省份表.xlsx")

```

