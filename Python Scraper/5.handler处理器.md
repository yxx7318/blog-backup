# handler处理器

## 基本使用

```python
import urllib.request

url = 'http://www.baidu.com'

headers = {
    "User-Agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 '
                  'Safari/537.36 Edg/111.0.1661.62 '
}

request = urllib.request.Request(url=url, headers=headers)

# 1.获取handler对象
handler = urllib.request.HTTPHandler()

# 2.获取opener对象
opener = urllib.request.build_opener(handler)

# 3.调用open方法
response = opener.open(request)

content = response.read().decode("UTF-8")

print(content)

```

## 代理ip

通过ip下的服务器去访问资源

```python
import urllib.request

url = 'https://www.baidu.com/'

headers = {
    "User-Agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 '
                  'Safari/537.36 Edg/111.0.1661.62 ',
}

request = urllib.request.Request(url=url, headers=headers)

# 通过快代理获取代理id——http对应http的地址，https对应https的地址
proxies = {
    'http': '221.5.80.66:3128',
    'https': '221.5.80.66:3128'
}

# 1.获取handler对象(ProxyHandler()方法)
handler = urllib.request.ProxyHandler(proxies=proxies)

# 2.获取opener对象
opener = urllib.request.build_opener(handler)

# 3.调用open方法
response = opener.open(request)

content = response.read().decode("UTF-8")

with open('baidu.html', 'w', encoding="UTF-8") as fp:
    fp.write(content)

```

## 代理池

```python
import urllib.request
import random

url = 'http://www.baidu.com/'

headers = {
    "User-Agent": 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 '
                  'Safari/537.36 Edg/111.0.1661.62 ',
}

request = urllib.request.Request(url=url, headers=headers)

# 通过快代理获取代理id——http对应http的地址，https对应https的地址
proxies_pool = [
    {'http': '117.114.149.66:55443'},
    {'http': '118.24.219.151:16817'}
]

# choice()方法随机挑选一个列表中的元素
proxies = random.choice(proxies_pool)

# 1.获取handler对象(ProxyHandler()方法)
handler = urllib.request.ProxyHandler(proxies=proxies)

# 2.获取opener对象
opener = urllib.request.build_opener(handler)

# 3.调用open方法
response = opener.open(request)

content = response.read().decode("UTF-8")

with open('baidu.html', 'w', encoding="UTF-8") as fp:
    fp.write(content)

```

